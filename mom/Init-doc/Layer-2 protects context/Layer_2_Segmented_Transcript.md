## Segment 1 – Meeting Verification and Agenda Setting
Call with Yogesh V - 20260107_105629 - Meeting Recording
January 7, 2026, 5:26 AM
1h 3m 4s
Yogesh V started transcription.
Yogesh V 0:10
Yeah. So actually, you're Balan; NSL doesn't know the link on the conversion. That job role, as in, it is a different role.
So Adabati, basically no. So I don't know either; my export money or skills like transfer to its store will set up a training plan using Gemini to guide learning cloud skills. So, apply the knowledge-based knowledge graph into a real-time project. Really, the production and the customer acquisition.
Product thinking and system thinking. Then we need to create some cheat sheet, mind map flow for the competency system, product customers, business tools, techniques, and approaches. So apply this into PLP. What is that PLP UI? No, we wouldn't do this whole concept.
Other based machine learning tool, Mario? OK, is the full form in it? People Planning Platform. OK, Personal Planning Platform; I'm like, OK, OK, OK. I'm planning to collaborate on the Personal Planning Platform with BK.
OK, so firstly, we organize the context provider.
I know products using cloud-scale cursor.
OK. So are they going to? It doesn't have a part long. OK, OK, so now.
What will we discuss? So you pay in the level of us to initiate and understand money.
I can come.
OK, OK. So document. OK. OK.
Screenshot Nirav.
In.
I'm not personal. What do you know in the model M2M1/M2M1 Pro?
Not a lot of this point again. Oh, smooth at home.
Uh.
The.
Other context on the context; then we will take the next action, the technical breakdown already.
OK.
None.
Doing something.
That's niceline.com space for me, an interactive platform. I'm not my video; I'm over contact user devotion gate.
On the learning examples, gap analysis and assessment.
That teammate's video or four times user to our questions to get our understanding of you.
Then I wouldn't join an actual content account. Even when, OK, yeah.
OK.
OK, either the object you want to have a quick...
Malibu then?
On the left of now, Bharat, OK.

## Segment 2 – Definition of Flow Intelligence and Learning Analogy
This discussion is about documenting documents, and this is insight from 2 sessions regarding the development of an AI tool for the upcoming hackathon. OK, focusing on the concept of "Flow Intelligence" and its...
Application in education and engineering workflows. The team is building a solution for Google. I have learning of professional development, the core concept to solve. So our employee intelligence, the ability to solve problems and learn new concepts rapidly without a prior...
Leveraging their lost knowledge basis, OK? The discussion covered several potential projects. OK, either on the last OK. OK.
OK, OK. Yeah, this is fine.
In our...
OK, now I'm recording text, either one there.
OK.
Hello.
Hi, bus travelling.
It said OK on the... like nano became.
OK.
Bye.
Out of the... out on the tone or two minutes more than on the run, we look at the...
Yeah.
Then the...
Welcome.
In the call 11 to 12, Vikram.
And then.
We will see. Then we will reflect on it.
In energy... in the alternate this.
Sunday, Sunday. Must. Yeah, we can do Saturday, Sunday also.
It's multiple and all the rest time.
Actually, it is true and it is fun from now. OK well.
Morning.
People on the document about that. Hmm. Fluid Intelligence plus. Hmm. Crystal PLP. No, no, nine PLP... may OC garamista. Get out of there. You know, first nice landing.
OK.
But connect many, but then there no only are.
It's down.
That's it. I'm regarding it. OK. And the group will be getting Slack. No, no, no, no. That's it. Only nine week one talk. All groups are created on...
No, it's a group.
OK, but the document? The document localized CT software? That's like the local edge.
Let's beat local, OK.
So in this right, you've got the overall idea, right? Yeah. You'll explore only the UI part. In the UI part, we were discussing the base fluid documentation—that one and the last part we were discussing. Right. We tried to have some 2-3 views, and he's editing the content.
Like guided learning and making questions for each context. Then... So what about the last thing I discussed with that? Actual core logic implementation is doing it, and he's exporting files in the form of JSON and existing...
On delta. So this one, I understood: we are going to apply fluid intelligence, and we have one part like the TMD editor kind of thing, and one more core is we have the Personalized Planning Platform. So what we are going to provide is...
Let's consider that is some one-hour video. We are going to give some individual in-between breaks, and we will ask interactive questions. Yes, that is the core idea. The interactive questions and the responses—then summarize it in the mind map.
The view. OK, right. See. Basically, we're going and fetching the very, very core part of...
The knowledge... what is the core part of knowledge is our language. Yes, the language. I know you and he, it's maybe common understanding. Understanding. Yes. Understanding. So what is intelligence understanding? No, no, no, different. 3 iterations in five words.
OK.
Inter, did you put MD on that day? No. We need to reflect on it. No, we didn't even put it right. No, no, we didn't get 10 days. We were just presenting on some laptops. They asked for the prompt. Ashik asked the prompt. That's it. OK. We need to reflect.
OK, that reflection. So what is... how do you define intelligence signal? Five or six words... between that, on the day-centric, 2 words; it is coming to my mind on this very core part for me to distinguish.
Distinguish the differences; distinguish between the intelligence, between differences, between differences and common things between things. Then you can tell he's explaining about intelligence and the word 'evidence' and one solter. OK, super. That's all right. OK.
OK, so which means... why was I born as a child? I don't know anything. I interact with my parents. I learn some language, some habits. I learn some skills. I come to school with my friends.
I learn something new. How do I learn new things? So what do I know so far? Then I'm hearing something new. A word. Something that... that's with the one word my friend is saying. "Love you." That's what he'll tell. "Love you." What is what? Friends will tell me.
"You're so mean." Mm-hmm. OK. I am a child. A six-year-old child. I'm coming from home. I'm going to school first today; due to some interactions, one of my friends asked me... "You're so mean."
How many points will you know going forward? Gokul will review with you and car.
So I'm sitting in the school. I heard the statement, "You are so mean." I don't understand. At the end of the day, I'm going to go. I'm asking my mom, "Hey, Mom. What does 'mean' mean?" Hey, Mom will try to understand. In what context? You guys got into this statement. Then the kid will explain: "Me and my friend were interacting."
"We got into a situation where my friend told me that I did so-and-so things; my friend didn't like it, and he told me that I was so mean. What is the meaning of 'mean'?" Then Mom would like to explain it: "Accha beta, one month back we had an incident. There was a situation."
Like there was some misunderstanding and there two people had different opinions, right? One person... but they are different.
Right. So one person's opinion may look like 'mean' to the other person, but both are right from their own perspective. I get Mom will try to give the explanation for that context, for that word meaning, by keeping some analogies to the incident that already happened. So that they can easily connect it.
And they can think how to go and resolve it, right? How to resolve the conflict, right? So the core part is language.
So our language... So if we consider software, like we are hiring somebody coming to the team, the workflow, the process they are following, technical skills—what is required is almost 80% new for them and how they will adapt.
Right. First, they need to understand our process, our communication. They need to understand it. So for each word that we use in the conversation, they need to deep dive and understand the meaning with respect to their existing knowledge base.
That is what intelligence is: I know something, but I learn... I am coming across some new situation, new words, new statements, new contexts. How do I make that new statement—compare the new statement with my existing things—and make that difference? "Oh, I know this."
"But this is additional on top of this, and this is something similar." Using analogies like that, they can understand it so that they can follow and apply it in their daily life.
Thank you, intelligence.
How do you define it? List... So we have worked with the two analyses, kind of two stories they sent, right? The code parts.
Distinguish differences right between entities and relationships. Common, everything... the specifications. Generic things will be done, then very specific things, right? Your emotions, your understanding, right? This is...
You can put it together and say "intelligence". Then if, in the flow rate, firstly what we'll know...
"Learn" is the first word, then "understand", right? We take some meaning out of it. Then we reason it; we will ask questions. "Hey, why this? Why not this?" Then we act to judge correctly. Then we can take a decision, right? Then we can build a skill set.
Then we can solve a real problem.
Right. Still, solving a real-time function is intelligence. OK, you got it? Yeah.

## Segment 3 – Engineering Workflows: Cognition vs. Computation
Perfect. So now let's go back to the... we'll be zooming 10 minutes back. Whatever we're discussing, we need to develop the UI document, custom drive, or use an open-source platform so that...
If there's a technical context which explains about software engineering.
And after 10 minutes, it's covered. One topic is covered in that. Then stop it; then use the reasoning questions. Then the candidate will respond. Yeah, but again, the candidate will ask some more questions. "I don't understand this. Explain in simple terms." Then again, we'll make calls.
Then we will update those things in different views, right. We'll try to put the layers of what we are learning now on your... like layer one, layer two, layer three, like that. Does it so that they can see everything as A1, NSC, quantum, NSC, OK, right. So you can use 3 views; 5 is completely personalized.
You guys understand? Yeah. Yeah. So this will be very... This is a must platform. Why? We are doing this when we are changing the workflow, which means like we have a traditional software engineering workflow.
Like you understand, read the specifications, memorize it, build the knowledge, listen to somebody... the team will understand that you will. The leads will enhance their understanding. Then they'll try to design the system. They'll understand the user pain points. They'll derive the specifications, right.
On specifications. Then again, they'll go for architecture design. They develop, test, release in tenants, customer bug again, fine tune. This is a loop.
Right. So we keep all the things whatever discussed now is one part of the brain. Then we'll jump into the code. We'll write it. These are the problems; I'm writing code. The code. We'll take inputs. Code is very deterministic. It's computation, right? So.
It will take input, process, it will output. It's very much fixed, right? It's dynamic but it's... it's not very fluid. But if you take cognition—our engineers, right—we are just... we're pouring, right? But our brain is...
It's... it's not computation, it's cognition, right? It can zoom in to a specific case. It can write a code; it can zoom out under it; it can understand the entire context. Or the user can give you this input, or the user can give this input wrongly, or the user may not give the response.
Right, zoom out. It can ID it all. The use process. Then you can try to handle the core extended non-functional equivalence, right? This is what our cognitive... cognitive picture is. OK, right. So the traditional, whatever we discussed now, is a traditional way. But now agency play.
So in all the phases, the same thing; but in each phase of engineering, what percentage of agent assistance we are going to take to accelerate the process? Oh, requirement is there. I know the high-level context. I'm going to keep it right. I spent some 10% effort.
That remaining 40%, agent... Agent A will develop it; 50% of the requirement is done. I visualize it, the 50% understand it, validate it, fine tune it, then I'm taking a 50% requirement, right. I'm like giving my goal to do the design. "Yeah, I want to develop a modular application."
They would apply into my two or three products. I have a USB wireless power charging sniffer. These are the requirements I have down the line for the next three years, but I'm going to develop a very robust modular platform. Then I'm going to build modular components on top of it so that when technology evolves, requirement changes, I can easily address my requirement changes.
Like that, you... you... your inputs, your domain problems; then you'll try to take this... is some 10% or 20% of the design you give it to your AI system that will give you something that you consider like 50% of the design is done. You will find to validate it right, some 60-70% you will make sure you are making the progress.
Right. Then again, you'll take that until you release a solution. You'll try to implement it. For implementing, again, you'll ask for the AI agent: "Make a plan, implementation plan, parallel plan, right? UI, back end, database integration, everything parallel, four or five plans." It'll go everything then.
Again, in the development, we will give the context 10%. It will make some 50% effort. Then we will validate it; then we'll see the results. We'll benchmark it—functional, non-functional requirements. How it is realized in the report.
From the design, the traceability requirements to design to development, to testing, to reports—everything is traceable. Then you're getting a full visualization, right. So from the beginning of the top I copy we...
It.

## Segment 4 – Challenges in Communication and Vision Alignment
In our measurement—very average measurement, approximate measurement—you reason only 70% accuracy. Hmm. So why will you not get 100% accuracy in the first iteration? Why?
In general, or it doesn't in general?
Because in all... in my last 10 minutes, I was telling 10%, 50%, 60%... not paying attention, or we will pay attention. But in my mind, parallely, my mind will ask multiple questions. When you're explaining the scenario, I got the core idea I was trying to understand whenever...
You are saying something, right? My mind is going to some other topic. Trying to connect: why is this we need to do in this way, or...?
How we are going to arrange the solution? It should not be in this way, but it started to think in that way. Yeah, exactly one of the 10 minutes. I'm throwing a lot of context, throwing a lot of statements, jumping, jumping, switching the context, zooming out, zooming and zooming in. When I was saying number and zooming it. Yeah, switching requirement, designing, and zooming.
Out, right. So your mind will try to see, "Hey, has to zoom in, how I'm going to design it." Yes, it's pattern. "I'm going to zoom out, it's pattern. Hey, Microsoft we sell, right." I got it, zooming in. So what I have... it's not a problem; it may be a problem with you guys, or it may be a problem with mine also.
I should not. I should not throw the entire flow like this. Or I can also say like... I can also say that, "Hey, this is a vision. I'm setting a vision, right? I am not entering any of this." So you can... or something... or you execute it, yeah.
I'm sharing this to generate a vision so you guys have freedom to go on. Just put your mind in a very, very, very open space and do whatever you want, but do a reflection. Yes, right. This call. If you do a reflection, connect all the dots, you can understand the vision. So vision, you can understand in 5 minutes or 10 minutes.
This discussion, take it for two weeks. Then you can get some sense out of the vision. You will have a lot of questions. Write up questions; again we'll do ideations, brainstorm. Then we can get the vision on top of the brain. So all three can talk the same language.
Why do you have to communicate the mission in the first place? Children should be in the same space during execution. We communicate, right?
We execute, build systems, and we verify systems, right? But all three of us have to do the same communication, right? So that we need to have the same mission. Only then, whatever you are telling, trying to communicate, I can understand. Same applies to all three, criss-cross.

## Segment 5 – Evolutionary Perspective and The Feedback Loop
Right. Do you understand the reason? No? Yeah. So why is it 70%? Why not 20% in the iteration one? Because of this thing; probably this is one of the reasons. What are other possible reasons?
How does the human brain... how many years it took to about to reach this stage from the stage it was before? From the ape, right, from the monkey, our brain... it came to a technology where you can send a rocket. It can plan. It is...
Doing.
Some crazy things like sitting in a data center in space, right? How it evolved, how much time it took? Lakhs of years, so billions of years, billions of years now. But from ape to this, I don't know; from the evolution, from origin to this, billions of years. But from ape to this, I don't know. Few thousand years, I don't know.
So the human brain, it always... I do things from different aspects, right. Try... try to understand the gravity, why the apple is falling, right? From the... what equations derived. But then we are applying into engineering, then we are seeing, bringing technology.
Right. What's applying that? We brought flight, invented flight aircraft, and it means of communication simpler, right?
Everything is an evolution, iterations in the... We cannot do that, right? So if we have a thinking that I'm going to direct the requirements going through the phases and then I'm going to release a product to a customer, it sucks. It will suck, right?
So this is a pattern that we have been following with our brain. So you go with 50%; you are understanding end to end. When you test it, you generate the artifacts metadata, you're logging in the debugger file, it will view: "This is output. This is this. This output." Each function is verified.
It's a nonfunctional requirement, also verified; this is a gap there. Now I will see. How do I fine-tune my architecture, like development techniques? Yeah. Requirements. Also sometimes software engineering the loop, right—there was some article, right? Yeah. So we keep cognition and computation. This is computation and this is computation.
Our brain is cognition. This is computation. But when we communicate, interact, collaborate both and build a system, right? So there has to be some connection, right? So we think something and but the system want to be realized is different. Mm-hmm. So it has to go for iteration. Version 2, Iteration 2, Iteration 3.
Then we can complete the loop and reach at least 90-95% accuracy. OK, but still 5% or 10% is still open. Why? Where is that?
I think you'd rather go to evolution. Yeah, that is a solution. OK, but what is...? What is that missing part here, which I didn't cover? Maybe one or two... Send one or two words. I might have told before in the vision. OK. Which part is missing to get the 100% or 99% from 90 to 95%?
Yeah.
You want understanding? Yeah. Different aspect. Human means... Who is it? Human. OK, let's go to the context. We are the ones building the system. Brain, you're using cognition, cognition.
System here, helping to accelerate, realize the solution, right. This is computation. Who? Who else? Human. You mean human? By engineers, developers, actual consumers, users, users and so users.
Do you think the user knows his problems? Everything? No, no, no. Give me some instances.
Some real-time analysis. Can you do me this? Human? Do not know that. What is their problem exactly?
Most humans will not think about the problems in the first analysis analogies.
I'm a user. I'm using some Word apps or I'm using...
Laptops I'm using, like I'm booking something in Airbnb; I'm travelling, going and staying and coming back—a lot of process I have to go through.
Right. Or I'm going to a doctor, right? I'm telling the symptoms. "I'm having a headache," right?
Then the Doctor will ask questions. "What you did yesterday? What you did the day before yesterday? What is the temperature?" The last series of questions. Then you write it right, or this is that might be like you might have been exposed to some cold air. See some change. Right. The temperature drop, right. He will write that in triple.
I cannot tell, "Hey, two days back I was exposed to the cold climate. Now I'm getting a cold." But I don't know my problem. I'm a user. I'm going to the doctor. The Doctor will ask a series of questions. From that, the doctor can diagnose one or two possible solutions. He'll give medication.
He will knock out one by one, then finally he can connect it. It's a loop, right? He'll give some medication. So what's known is that you're consuming medication and again it maybe gets resolved, or if it's not resolved, we'll go back to the doctor. What will the doctor tell? "Oh, I have 3 possible diagnoses. 1..."
They checked it. "No, it's not working." And then I'll get a second set of medications. He'll tell, "I'll increase those unchanged... that this... something like that." Then it may work. Then he will go for... still if it does not work, he'll tell, "Go for consulting different doctors." Not after. What is that?
Different tests mean... with different tests go for its rate or local type of diagnosis. It's a loop, right?
So for my back pain, I consulted more than 16.
Making cleaning... some medications. I made the color for the... then answer for the right... each certain things I cannot connect. What solution has it given to me? But certain things give me some 20%, 30%.
What is the solution? So I have to blend; so finally some four or five solutions I would adapt like later, and I have to understand my body. "Then in the time I need to do this exercise, in this position I need to maintain. I should not sit for long term. I should sleep in this posture."
All those things. "While driving I should not drive for a long time. After one hour, take a break." I just find a lot of techniques applied for running... then I get rid of my back pain being chronic to somewhat controlled.
Level, right? So it took this much... a year for me? More than eight years, more than 16 consultations. Different then learning about myself to find a solution.
So I'm a user, right? So there is a system mitigation system. Is AI... I am a user, took 16 years, right? There is no solution. Maybe now with the AI, they may be able to understand each and every node, or maybe get down the line after 5... four or five years.
They can... within one or two weeks they can access different problems, and instead of 16 years of different things, we are to unify the medication. So it's a different option completely in different, some other time. Right. So the user, as you said, does not know what is the problem. So.
We're taking the first draft, giving it to the user. The user will see, he'll give feedback. "Yes. Yeah, I see something here, but if it's something... if you have one more extra volume with this information, I think it will be value-added form, I think." Then again we'll add it—second iteration, second iteration. Then you'll ask. "Yeah. I need a voice input. You have so much input. Simplify it."
You're more than excess. Apparently you're more than 30 user inputs. You simplify it, right? Then first level it's only 5. "What is your level? You're working on? Protocol, physical power." Then accordingly, we will go expose the remaining, or we have voice interaction. You define your problem. "I know the knowledge base of the specification."
I will come and give you suggestions. "These are the things you need to verify, and verify you're in the behavior, right." Those kind of things we can bring in so that we can reduce the customer's time and effort to solve their problem.
Right, this is just interesting. Similarly, any problem trying to solve product thinking, understanding users. So it's... it's like this: how sooner you're going to the customer taking the feedback, applying it, applying data? Then only you'll come up with some 95% to 99%.
Accuracy. OK, right. When customer changes problems with this, the system goes running forever.

## Segment 6 – Project Roadmap and Content Generation Strategy
Correct. You guys got the vision service with the UI for that. Yeah, building the core engine, it'll break the system, some static content, but for some part we are... we are working one or two problems at a time.
Mm-hmm. Right. The content generation part is working on it. Content generation—when you are talking about that, right, I can connect: me and Vaishnavi and Hitesh have been trying to use that paragraph-by-paragraph data generation right from the transcription.
That don't need that of connecting... with it is coming, it is coming.
Yeah, because this is very, very important. If you ask me to do the same story after two days, no one can do it, right? Make reach 80% or I may reach 70%, or there is a very less possibility I may go to 30%.
But the amount of sunlight... the energy I spent with you, this going finding information from different neurons and putting it on, currently giving it right... it's energy.
Right. I consumed 50% of my cognition load for today, right?
Yeah, so UI, UI. So... so one action item, what I would say is: so so far we have discussions like four page discussions and some context. We have taken it. That context would still organize it. What context do we need to pick and give it to the tool, something like the Manus?
And our objective goal and what exactly we're going to do in Phase One—give it, it will light it and you need to do it—build an architecture diagram, flow diagram, everything. Its component we'll understand. Then we will test it while testing.
The outcome, the functionality and nonfunctional results. Based on that, we will again ask questions. Which component is causing problems in the nonfunctional requirements and which problem is having less accuracy in the functional? We'll try to put alternate components, libraries; then version one, version 2, version three, we can iterate it. Then we can build a system which can...
Solve a single problem.
Right. OK. So this is a technique for building anything, but we can take the UI like... first in this open source libraries, we can use it in the first version. Later it comes in. How much of it wants... let it have how much bug it wants. But once you start seeing the output then you can...
Complete the loop. Mm-hmm. Right. You need to put yourself as the engineer, builder, or creator for three days. 4th day: you need to put yourself as a user.
Right. Put all the feedback. Now you'll get a different thought process for the customized requirement. How to fine-tune the implementation methodologies, your design techniques? Right, different parallel possibilities, benchmarking. Then you come up with a robust system.
OK.
Understand. Yeah. OK. Context. Organize. Stop.
This is over you.
The core problem we are trying to solve and these are the models we have; I think this is based on the last recording. We'll go to some other MD files, whatever we ended earlier.
So we need to set the goal and we need to do the first. Small POC is for the separation. You're doing the back end, the core engine, right? It's already seeing some output. Yeah, that we need to review. Review, right? Actually, we'll complete this organizing the text. Right. You take some 4.3, right, and then we are talking.
Yeah. So we'll take all the discussion points. Everything is there in MD, right? Yeah. Transcription. All the MD files. You will take it until... Hey.

## Segment 7 – UI/UX Prototype Technical Details
To develop, to generate the context for building the UI component for this platform, identify the goals from the discussion points. Should we open ChatGPT and then?
Yeah, uh, we have to ChatGPT on the GRL text cloud over morning here.
OK. We can take from this transcript. Is this fine?
Yeah, yeah, yeah. Like... But I mean, between... OK, we'll probably stick with it.
Yeah, if Mike enable panita.
Help me to...
Fine-tune this prompt.
By setting the goal from the input data that I have given here: different MD files.
Identify the goal to build 1.
Building the UI component of this PLP platform.
The first prototype.
To render the...
Data generated from the prototype of the core engine.
In different views.
Yeah.
Now we'll go to the MD files to help me to find this round file setting to go from, you know, going to take that you able to create MD bytes now.
I... I think identified battle draft in Boria.
After going.
Of the code to build the UI component. It's been good now using Manus.
Manage a cursor in a clock cursor. A lot of minus ideal clock.
The.
How do you take the stand from the ChatGPT? Yes, using ChatGPT.
OK. And let's do the... like it's like initial.
Problem definition on the requirements using ChatGPT execution... implementation using either as well as not anything, right?
In the top basement.
Problem definition and then the barrier of other things. It is in that our English.
If you're OK MD file, only the failure. I'm not. I'm only going to test it with the phone. I'll go where you only receive a prototype, one minute. OK, then maybe select, you know. Copy this when you put the you know.
Even then, the... and that you will have implementation.
Using.
Man, I'm sorry. Perceptive.
OK.
And the end audio company, we need the transcript with it.
But one usual addition and the unification.
It means it on that list and run relax like.
See this discussion point. Different level also don't know any experience.
It isn't listed good for your code engine implementation, right? Is that... does it have any connection to the UI?
1 speaker... I just wanted to use engagement to... In fact, we'll ask, see if you're opponent right after 10 minutes they will be out. So you'll need to monitor.
Then how much the involvement they have? Accordingly, you know the stories and they are feeling very rosy or new. And you need to discuss. OK. OK. Yeah.
I do you goto.com.
Yeah.
Hey.
Contexts... which one of code are they? Contacts, but they're essentially the contacts doing something else.
What it has to do... that file lines, how much levels it has to the UI, even the UI that right... then put it go for the next paragraph. OK, come this and put it. Come with this. Go do action only. This so that you don't have to come back here again. First me another copy with spending go and I think putting the thing for that.
Yeah.
You don't think you can run on the platform UI component using platform using the portal control expanding using.
Space. Yeah, using the platform for... for using platform for problem definition or requirement using ChatGPT execution... ChatGPT and execution implementation using the particular ChatGPT and execution implementation.
Using Manus, our cursor first prototype to render the data on the mother copy this particular on the.
On the 1st 2 transcript.
The transcript, under competition and competition markers. OK, and the group description; the group is then there is Google or rather giant monitors. They... they know that they solve many problems it can.
On your customers based on... but the third one, the data on privacy technical implementation.
With a significant proportion of talk focuses on data and noting that you will restrict the particular set, it will be restricted about the OK on the data policy. But now letting we just told the script different speakers through frequency and modeling so they observe.
Either in the back end models of organize next one, the fluid intelligence. Yeah, I do without any gramme. Yes. Then propose to solution. And what's splitting the same? Yeah. Either to the class. Either pick up with 20 clock in the.
OK, editor.
OK, as a meeting concludes, the team decides to take this and then discuss a little bit from the local compute using the long enough analogy for the team of which is like building a custom car or being the MD failing.
That's OK, I'll do the Radha. The ending on being 20 and the OK either in the modules or module.
So we don't do the modules left first module anything OK we do on the and the objective.
Yeah.
You know, first thing, I don't need them views speaker together focus on content.
Internet, Internet layout; I don't know.
Of course.
Anything, I forget password code... they don't password. OK, password.
It is a fine-tuned gold prompt you can paste into that GPT/Manus server. So to try the UI build for your PLP platform based on input data you shared interactive learning, dynamic personalization for panel.
The screen EAA process to ask questions... my mind maps diagrams IQ, baseline, Curiosity injection. First the summary's OK; you can also try fine-tuning on the goal for PLP product plus UX plus.
PLP the UI will render and then show this data... so this way so generates questions. User engagement in this HQ, basement, understanding level, summarize and mind maps diagrams. PST comes contents in this.
Primary goal: building a working UI component prototype that can take mock JSON outputs from the core engine from different MD files and enter them into multiple interactive views. This prototype is focused on problem definition plus vector once validating.
Using transit team and execution product problem definition from input data... lose engagement during broadcasting; the platform must monitor involvement continuously. Example: after 10 minutes they may drop off.
Interrupt at the right time to ask questions and re-engage like quotes. Jim End times and then continue. Adapt content dynamically based on each user's behavior, plus understanding. All provide visual-first learning gates, mind maps, diagrams.
Two-word summaries, just like cues instead of long text Qs. Curiosity injection. So just questions to help users learn how to ask their phone prototypes. Go Phase One UI: create a single landing screen that supports 4 panels with screen layout. Then the main session view.
Split into core section while Media/podcast content displaying and the top Left Media podcast play area marked if needed. Top break a pass plus question. Current question answering for submit and I'll see bottom left visual intelligence.
That'd be 400 QSP injection, quick summaries, two word summary part, suggested questions we should close. OK, engagement monitoring for slight paper include an engagement monitor widget shows, engagement level high, medium, low; shows a drop-off risk after time.
10 minutes checkpoint to the UI prompts micro actions from like stretches, jump, quick activity when engagement is low. OK, adaptive content flow when user answers your question, update the user understanding level like previously now.
Proxy update next to recommended question said update mind map or diagram not OK update curiosity prompts OK in the notes node level, the adaptive content flow level the OK as they've used on that on the different.
Add simple top time to switch between session view. OK, four panel and mind map. Full screen diagram. Full screen inside timeline in one data contract line and asking the UI rescue. So yeah you can connect so high level.
Yeah, right. I just do one mock up, right. Can go to Descript.
Type this Descript demo.
This go to... go to Google, type this demo.
Yeah, go with the first one.
Yeah, I think the market... Scroll down.
A little on the image.
Yeah. Thanks.
OK, this is a fact.
Audio processing, right text to it... has a lot of features like this is one UI is interacting with the user and this is a different all of this I can say like first of all if we are experienced we have connect variable with the text.
Right, 20% on which hundred based on the text, right? So I want a view for the text right after that.
The... the video will go on here, then the podcast. Hmm. Right. Start over here. Right. And then.
After one minute, some context discovered that mind map high-level view, zooming view. Here we can put the zoom out view mind map.
With some infographics, images. Right. Well, you can be able to...
We can give the data to the user so that they can zoom in and zoom out again just from zoom-in view and zoom-out view.
Right. So basically what happens is if you have like one paragraph here and select three paragraphs in the text, is that under whenever the recording is, the focus is going on, we can highlight each.
You get the attention, which part of the text is being from... OK, right, but sometimes by only listening to audio we can generate some understanding, but by looking up to it, right, out of memory will trigger action memory to trigger captions. Yeah, the paragraph before it paragraph quickly you can make some.
They come back here right then after one minute you can see the overview. Then we can ask for other questions again. We can expand them right again. For those questions, you can expand this. So here we can put the kind of restrict.
The usual. Then your questions content. Then you can easily navigate it right then, while clicking here also they can navigate it.
That's it. Navigation is important. Zooming or zooming in like that. You got a point, right?
Like that you can put some layout maybe in Figma or something, right? You can try to take: this is navigation component, Content Department site, and that we can do idea something then try to.
For this we can try to use some open source. This is actually everything is output right, not very interactive. It's just click clicking on linking right like in the next level each this component we can take it mind a map or to customize it if from some other.
It's like everything. They cannot give any redo it. They will get some idea. They may try to go and add one more here, modify, expand, add some images right, further custom changes or document edition. Custom documents. Yeah, that explodes differently, that's active.
OK, right. That's a deep value we can do with this that can become... It's like it's one of the good solutions, OK. Problems. OK. It can... we can apply this to anywhere. This... this... this way and like borrow this also.
OK.
Right. Scroll down, wait for some other thing. You can take one screenshot and put it there.
Free chat. Yeah. And the key that I'll go somewhere to compare 9 the calendar. Hmm. Yeah. Sound down. There's one.
Start up.
No.
Yeah. Do you look at this, it is highlighting, right? Mm-hmm. So like this, we can just write it as in many codes. Mm-hmm. Skype. Scroll down.
In C3.ai there is one image right? Can you take, give it?
Last time we discussed the... the last comment Descript so it's Descript 10 of.
Is the one.
When you play it right, it will highlight it. What is that? OK, what is the current text or word? OK.
Tell me now and on this next one.
We... here we can each context which is covered in the partners. You can add it and add it in different colors. Then we can put some text together. These are complex in this part, in that part, something OK.
Nothing. What's it, finished?
Yeah. Have you got some idea? I will prepare from for some.
OK, let's OK.
(Empty)
Balasubramanian K stopped transcription.
